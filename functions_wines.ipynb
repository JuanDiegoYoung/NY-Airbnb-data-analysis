{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_boxplot_from_list(data: list, title: str) -> None:\n",
    "    \"\"\"\n",
    "    Muestra un boxplot horizontal para visualizar anomalías en precios.\n",
    "\n",
    "    Parámetros:\n",
    "    data : list\n",
    "        Lista de valores numéricos a graficar.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 2))\n",
    "    plt.boxplot(data, vert=False)\n",
    "    plt.grid(True)\n",
    "    plt.xlabel(\"value\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_corr_with_target(df: pd.DataFrame, target: str = 'quality') -> None:\n",
    "    \"\"\"\n",
    "    Plots a horizontal barplot showing the absolute correlation of all numeric features with the target variable.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        The input DataFrame containing features and the target.\n",
    "    target : str\n",
    "        The name of the target column to correlate against. Defaults to 'quality'.\n",
    "    \"\"\"\n",
    "    corrs = df.corr(numeric_only=True)[target].drop(target).sort_values(key=abs, ascending=False)\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    sns.barplot(x=corrs.values, y=corrs.index, palette='coolwarm')\n",
    "    plt.title(f'Correlation with {target}')\n",
    "    plt.xlabel('Correlation')\n",
    "    plt.grid(True, axis='x', linestyle='--', alpha=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_modelos_regresion(\n",
    "    X_train: pd.DataFrame,\n",
    "    X_test: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    "    y_test: pd.Series,\n",
    "    usar_pesos: bool = False\n",
    ") -> tuple[np.ndarray, np.ndarray, float, float]:\n",
    "    \"\"\"\n",
    "    Entrena y evalúa dos modelos de regresión (LinearRegression y GradientBoostingRegressor)\n",
    "    usando RMSE como métrica. Opcionalmente aplica pesos balanceados por clase.\n",
    "\n",
    "    Parámetros:\n",
    "    ----------\n",
    "    X_train : pd.DataFrame. Conjunto de entrenamiento (features).\n",
    "    X_test : pd.DataFrame. Conjunto de prueba (features).\n",
    "    y_train : pd.Series. Variable objetivo de entrenamiento.\n",
    "    y_test : pd.Series. Variable objetivo de prueba.\n",
    "    usar_pesos : bool, opcional. Si es True, utiliza pesos balanceados por clase (por defecto: False).\n",
    "\n",
    "    Retorna:\n",
    "    -------\n",
    "    y_pred_lr : np.ndarray. Predicciones del modelo LinearRegression.\n",
    "    y_pred_gbr : np.ndarray. Predicciones del modelo GradientBoostingRegressor.\n",
    "    rmse_lr : float. RMSE del modelo LinearRegression.\n",
    "    rmse_gbr : float. RMSE del modelo GradientBoostingRegressor.\n",
    "    \"\"\"\n",
    "    sample_weight = None\n",
    "    if usar_pesos:\n",
    "        sample_weight = compute_sample_weight(class_weight='balanced', y=y_train.astype(int))\n",
    "\n",
    "    lr = LinearRegression()\n",
    "    gbr = GradientBoostingRegressor(n_estimators=100, max_depth=6, learning_rate=0.1, random_state=42)\n",
    "\n",
    "    lr.fit(X_train, y_train, sample_weight=sample_weight)\n",
    "    gbr.fit(X_train, y_train, sample_weight=sample_weight)\n",
    "\n",
    "    y_pred_lr = lr.predict(X_test)\n",
    "    y_pred_gbr = gbr.predict(X_test)\n",
    "\n",
    "    rmse_lr = np.sqrt(mean_squared_error(y_test, y_pred_lr))\n",
    "    rmse_gbr = np.sqrt(mean_squared_error(y_test, y_pred_gbr))\n",
    "\n",
    "    print(f\"RMSE logistic regression: {rmse_lr:.3f}\")\n",
    "    print(f\"RMSE gradient boosting:   {rmse_gbr:.3f}\")\n",
    "\n",
    "    return y_pred_lr, y_pred_gbr, rmse_lr, rmse_gbr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_metricas(y_pred: np.ndarray, y_true: pd.Series, modelo: str) -> None:\n",
    "    \"\"\"\n",
    "    Calcula e imprime métricas de clasificación (accuracy, precision, recall y F1-score) \n",
    "    tanto globales como por clase. Asume que y_pred proviene de un modelo regresor \n",
    "    y por lo tanto debe ser redondeado.\n",
    "\n",
    "    Parámetros:\n",
    "    ----------\n",
    "    y_pred : np.ndarray. Predicciones del modelo (valores continuos a redondear).\n",
    "    y_true : pd.Series. Valores reales de la variable objetivo.\n",
    "    modelo : str. Nombre del modelo a mostrar en los encabezados.\n",
    "    \"\"\"\n",
    "    y_pred_int = np.round(y_pred).astype(int)\n",
    "    y_true_int = y_true.astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_true_int, y_pred_int)\n",
    "\n",
    "    print(f\"\\n=== Métricas globales para {modelo} ===\")\n",
    "    print(f\"Accuracy: {100 * acc:.2f} %\")    \n",
    "    print(f\"Precision macro:    {precision_score(y_true_int, y_pred_int, average='macro'):.3f}\")\n",
    "    print(f\"Recall macro:       {recall_score(y_true_int, y_pred_int, average='macro'):.3f}\")\n",
    "    print(f\"F1 macro:           {f1_score(y_true_int, y_pred_int, average='macro'):.3f}\")\n",
    "    print(\"\\n--- Métricas por clase ---\")\n",
    "    clases = np.unique(y_true_int)\n",
    "    prec_none = precision_score(y_true_int, y_pred_int, average=None)\n",
    "    rec_none = recall_score(y_true_int, y_pred_int, average=None)\n",
    "    f1_none = f1_score(y_true_int, y_pred_int, average=None)\n",
    "\n",
    "    for i, c in enumerate(clases):\n",
    "        print(f\"Clase {c}: Precision = {prec_none[i]:.3f}, Recall = {rec_none[i]:.3f}, F1 = {f1_none[i]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenar_gradient_boosting_CV(\n",
    "    X_train: pd.DataFrame,\n",
    "    X_test: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    "    y_test: pd.Series,\n",
    "    grid: dict\n",
    ") -> tuple[np.ndarray, float]:\n",
    "    \"\"\"\n",
    "    Entrena un modelo Gradient Boosting con búsqueda de hiperparámetros mediante GridSearchCV\n",
    "    y evaluación usando RMSE. Utiliza sample weights balanceados por clase.\n",
    "\n",
    "    Parámetros:\n",
    "    ----------\n",
    "    X_train : pd.DataFrame. Conjunto de entrenamiento (features).\n",
    "    X_test : pd.DataFrame. Conjunto de prueba (features).\n",
    "    y_train : pd.Series. Variable objetivo de entrenamiento.\n",
    "    y_test : pd.Series. Variable objetivo de prueba.\n",
    "    grid : dict. Diccionario con los hiperparámetros a explorar en el GridSearch.\n",
    "\n",
    "    Retorna:\n",
    "    -------\n",
    "    y_pred : np.ndarray. Predicciones del modelo optimizado.\n",
    "    rmse : float. Raíz del error cuadrático medio sobre el conjunto de test.\n",
    "    \"\"\"\n",
    "    sample_weight = compute_sample_weight(class_weight='balanced', y=y_train.astype(int))\n",
    "\n",
    "    gbr_base = GradientBoostingRegressor(random_state=42)\n",
    "    gbr = GridSearchCV(\n",
    "        estimator=gbr_base,\n",
    "        param_grid=grid,\n",
    "        scoring='neg_root_mean_squared_error',\n",
    "        cv=5,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    gbr.fit(X_train, y_train, sample_weight=sample_weight)\n",
    "    y_pred = gbr.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "    print(f\"RMSE Gradient Boosting: {rmse:.3f}\")\n",
    "    print(f\"Mejores parámetros: {gbr.best_params_}\")\n",
    "\n",
    "    return y_pred, rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(\n",
    "    y_pred: np.ndarray,\n",
    "    y_true: pd.Series,\n",
    "    titulo: str = \"Matriz de confusión\"\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Genera y muestra una matriz de confusión a partir de predicciones continuas redondeadas.\n",
    "\n",
    "    Parámetros:\n",
    "    ----------\n",
    "    y_pred : np.ndarray. Predicciones del modelo (valores continuos que serán redondeados a enteros).\n",
    "    y_true : pd.Series. Valores reales de la variable objetivo.\n",
    "    titulo : str, opcional. Título del gráfico de la matriz de confusión. Por defecto: \"Matriz de confusión\".\n",
    "    \"\"\"\n",
    "    y_pred_clasificado = np.round(y_pred).astype(int)\n",
    "    y_true_clasificado = y_true.astype(int)\n",
    "\n",
    "    cm = confusion_matrix(y_true_clasificado, y_pred_clasificado)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot(cmap='Oranges', xticks_rotation=45)\n",
    "    plt.title(titulo)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_modelos_clasificacion(\n",
    "    X_train: pd.DataFrame,\n",
    "    X_test: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    "    usar_pesos: bool = False\n",
    ") -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Entrena modelos de clasificación (Logistic Regression y Gradient Boosting Classifier)\n",
    "    y devuelve sus predicciones sobre el conjunto de test.\n",
    "\n",
    "    Parámetros:\n",
    "    ----------\n",
    "    X_train : pd.DataFrame. Conjunto de entrenamiento (features).\n",
    "    X_test : pd.DataFrame. Conjunto de prueba (features).\n",
    "    y_train : pd.Series. Variable objetivo de entrenamiento.\n",
    "    usar_pesos : bool, opcional. Si es True, utiliza sample weights balanceados. Por defecto es False.\n",
    "\n",
    "    Retorna:\n",
    "    -------\n",
    "    lr_pred : np.ndarray. Predicciones del modelo Logistic Regression.\n",
    "    gb_pred : np.ndarray. Predicciones del modelo Gradient Boosting Classifier.\n",
    "    \"\"\"\n",
    "    sample_weight = None\n",
    "    if usar_pesos:\n",
    "        sample_weight = compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "\n",
    "    lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    gbc = GradientBoostingClassifier(n_estimators=100, max_depth=6, learning_rate=0.1, random_state=42)\n",
    "\n",
    "    lr.fit(X_train, y_train, sample_weight=sample_weight)\n",
    "    gbc.fit(X_train, y_train, sample_weight=sample_weight)\n",
    "\n",
    "    lr_pred = lr.predict(X_test)\n",
    "    gb_pred = gbc.predict(X_test)\n",
    "    return lr_pred, gb_pred\n",
    "\n",
    "\n",
    "def extraer_metricas_clasificacion(\n",
    "    y_pred: np.ndarray,\n",
    "    y_true: pd.Series,\n",
    "    modelo: str\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Imprime métricas de evaluación de clasificación: accuracy, precision, recall y F1,\n",
    "    tanto globales (macro) como por clase (None).\n",
    "\n",
    "    Parámetros:\n",
    "    ----------\n",
    "    y_pred : np.ndarray. Predicciones del modelo.\n",
    "    y_true : pd.Series. Valores reales de la variable objetivo.\n",
    "    modelo : str. Nombre del modelo (para mostrar en el encabezado).\n",
    "    \"\"\"\n",
    "    y_pred_int = y_pred.astype(int)\n",
    "    y_true_int = y_true.astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_true_int, y_pred_int)\n",
    "\n",
    "    print(f\"\\n=== Métricas globales para {modelo} ===\")\n",
    "    print(f\"Accuracy: {100 * acc:.2f} %\")    \n",
    "    print(f\"Precision macro:    {precision_score(y_true_int, y_pred_int, average='macro'):.3f}\")\n",
    "    print(f\"Recall macro:       {recall_score(y_true_int, y_pred_int, average='macro'):.3f}\")\n",
    "    print(f\"F1 macro:           {f1_score(y_true_int, y_pred_int, average='macro'):.3f}\")\n",
    "    print(\"\\n--- Métricas por clase ---\")\n",
    "    clases = np.unique(y_true_int)\n",
    "    prec_none = precision_score(y_true_int, y_pred_int, average=None)\n",
    "    rec_none = recall_score(y_true_int, y_pred_int, average=None)\n",
    "    f1_none = f1_score(y_true_int, y_pred_int, average=None)\n",
    "\n",
    "    for i, c in enumerate(clases):\n",
    "        print(f\"Clase {c}: Precision = {prec_none[i]:.3f}, Recall = {rec_none[i]:.3f}, F1 = {f1_none[i]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenar_gradient_boosting_CV_clasificacion(\n",
    "    X_train: pd.DataFrame,\n",
    "    X_test: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    "    y_test: pd.Series,\n",
    "    grid: dict\n",
    ") -> tuple[np.ndarray, float]:\n",
    "    \"\"\"\n",
    "    Entrena un modelo Gradient Boosting Classifier usando GridSearchCV para encontrar los mejores\n",
    "    hiperparámetros. Evalúa el modelo en el conjunto de test utilizando accuracy y muestra los\n",
    "    mejores parámetros encontrados. Usa sample weights balanceados.\n",
    "\n",
    "    Parámetros:\n",
    "    ----------\n",
    "    X_train : pd.DataFrame. Conjunto de entrenamiento (features).\n",
    "    X_test : pd.DataFrame. Conjunto de prueba (features).\n",
    "    y_train : pd.Series. Variable objetivo de entrenamiento.\n",
    "    y_test : pd.Series. Variable objetivo de prueba.\n",
    "    grid : dict. Diccionario con los hiperparámetros a explorar en el GridSearch.\n",
    "\n",
    "    Retorna:\n",
    "    -------\n",
    "    y_pred : np.ndarray. Predicciones del mejor modelo sobre el conjunto de test.\n",
    "    acc : float. Accuracy obtenido en el conjunto de test.\n",
    "    \"\"\"\n",
    "    sample_weight = compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "\n",
    "    gbc_base = GradientBoostingClassifier(random_state=42)\n",
    "    gbc = GridSearchCV(\n",
    "        estimator=gbc_base,\n",
    "        param_grid=grid,\n",
    "        scoring='accuracy',\n",
    "        cv=5,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    gbc.fit(X_train, y_train, sample_weight=sample_weight)\n",
    "    y_pred = gbc.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Accuracy Gradient Boosting: {100 * acc:.2f} %\")\n",
    "    print(f\"Mejores parámetros: {gbc.best_params_}\")\n",
    "\n",
    "    return y_pred, acc\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
